<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Custom News Feed | Promethean Blog</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Custom News Feed" />
<meta name="author" content="Leo" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Building the final custom news app" />
<meta property="og:description" content="Building the final custom news app" />
<link rel="canonical" href="https://github.promethean.dev/2018/01/24/custom.html" />
<meta property="og:url" content="https://github.promethean.dev/2018/01/24/custom.html" />
<meta property="og:site_name" content="Promethean Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-01-24T00:00:00+00:00" />
<script type="application/ld+json">
{"headline":"Custom News Feed","dateModified":"2018-01-24T00:00:00+00:00","datePublished":"2018-01-24T00:00:00+00:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://github.promethean.dev/2018/01/24/custom.html"},"author":{"@type":"Person","name":"Leo"},"url":"https://github.promethean.dev/2018/01/24/custom.html","description":"Building the final custom news app","@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="https://github.promethean.dev/feed.xml" title="Promethean Blog" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Promethean Blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog.html">Blog</a><a class="page-link" href="/">Home</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Custom News Feed</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2018-01-24T00:00:00+00:00" itemprop="datePublished">Jan 24, 2018
      </time>• <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span class="p-author h-card" itemprop="name">Leo</span></span></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h2 id="introduction">Introduction</h2>

<p>Principle is to build an email service app and flask web app that will deliver a daily email with 5 recommended articles based on what articles a person is interested in according to a machine learning algorithm. This will initally mean creating a model based on data pulled from pocket using the API. Laterly this will mean creating a service that will pull news from RSS feeds and testing them against the model to find top recommendations. Then creating a second service that will send out automatic emails with recommended articles.</p>

<h2 id="creating-supervised-dataset">Creating supervised dataset</h2>

<p>Using the Pocket API to create the initial dataset. Having curated a dataset by adding ~200 articles to pocket and tagged them with ‘y’ or ‘n’ depending on whether the user is interested in the article. Ultimately this will give a dataframe of article urls and a label of whether the user is interested or not.</p>

<h2 id="scraping-article-content">Scraping article content</h2>

<p>Once the URLs have been recovered it is necessary to scrape the text from these articles in order to carry out the NLP steps. This requires the use of scraping on a number of different web sources. This would be a time consuming process if I were to write a bespoke web scraper for each website. Therefore I decided to use an link embedding service with an api to query. Initially I tried to use embed.ly however this is now a very expensive paid service. I instead have used embed.rocks. This is tested below and applied to the whole list of article URLs from above.</p>

<p>Once the raw HTML has been extracted from the API, it was necessary to add just the text as a new column which is done using BeautifulSoup.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">urllib</span>
<span class="k">def</span> <span class="nf">get_html</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">qurl</span> <span class="o">=</span> <span class="n">urllib</span><span class="p">.</span><span class="n">parse</span><span class="p">.</span><span class="n">quote</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">rhtml</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">'https://api.embed.rocks/api/?url='</span> <span class="o">+</span> <span class="n">qurl</span> <span class="o">+</span> <span class="s">'&amp;key='</span> <span class="o">+</span> <span class="n">config</span><span class="p">.</span><span class="n">embed_rocks_key</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">ctnt</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="n">loads</span><span class="p">(</span><span class="n">rhtml</span><span class="p">.</span><span class="n">text</span><span class="p">).</span><span class="n">get</span><span class="p">(</span><span class="s">'article'</span><span class="p">)</span>
    <span class="k">except</span> <span class="nb">ValueError</span><span class="p">:</span>
        <span class="n">ctnt</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">return</span> <span class="n">ctnt</span>
<span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="s">'html'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'urls'</span><span class="p">].</span><span class="nb">map</span><span class="p">(</span><span class="n">get_html</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="k">def</span> <span class="nf">get_text</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s">'lxml'</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">soup</span><span class="p">.</span><span class="n">get_text</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">text</span>
<span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="s">'text'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'html'</span><span class="p">].</span><span class="nb">map</span><span class="p">(</span><span class="n">get_text</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="natural-language-processing">Natural Language Processing</h2>

<p>From the text column it is possible to call a vectorizer in order to turn the text data into a usable matrix format for Machine Learning.</p>

<p>For this project the <code class="language-plaintext highlighter-rouge">TfidfVectorizer</code> was used. This calculates a score for words based on the inverse of how commonly they occur. Thus rare words (which intuitively have greater explanatory power) are weighted most highly.</p>

<p>As well as this the <code class="language-plaintext highlighter-rouge">stop_words</code> argument was also called to eliminate the most common words (i.e. ‘the’, ‘a’, ‘said’ etc.) This gives the vector matrix the maximum possible explanatory power.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>
<span class="n">vect</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">stop_words</span><span class="o">=</span><span class="s">'english'</span><span class="p">,</span> <span class="n">min_df</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">vector_matrix</span> <span class="o">=</span> <span class="n">vect</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'text'</span><span class="p">])</span>
</code></pre></div></div>

<h2 id="support-vector-machines">Support Vector Machines</h2>

<p>Building a Support Vector Machine model from the vectorised data. This step will require some evaluation of the quality of the model. As well as simple building of the model a GridSearch cross validation was called to establish the most effective parameters to call. This also meant splitting the data into train/test in order to score the various parameter combinations.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVC</span><span class="p">,</span> <span class="n">SVC</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">vector_matrix</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s">'wanted'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">vector_matrix</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'wanted'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">"C"</span> <span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="s">"kernel"</span> <span class="p">:</span> <span class="p">[</span><span class="s">'rbf'</span><span class="p">],</span>
    <span class="s">"gamma"</span> <span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="p">}</span>

<span class="n">gridSearch</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">gridSearch</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span> <span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="n">best_model</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">best_estimator_</span>
<span class="n">best</span> <span class="o">=</span> <span class="n">best_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">best</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">'Score:</span><span class="se">\t</span><span class="s">'</span><span class="p">,</span> <span class="n">score</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="output-model-to-pickle">Output Model to Pickle</h2>

<p>This step involves pickling the model in order that it is callable from elsewhere in the system. In particular that it is callable by both the Flask app and by the script which will provide the email service from AWS.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pickle</span>
<span class="n">pickle</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="nb">open</span><span class="p">(</span><span class="s">r'news_model_pickle.pkl'</span><span class="p">,</span> <span class="s">'wb'</span><span class="p">))</span>
<span class="n">pickle</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">vect</span><span class="p">,</span> <span class="nb">open</span><span class="p">(</span><span class="s">r'news_vect_pickle.pkl'</span><span class="p">,</span> <span class="s">'wb'</span><span class="p">))</span>
</code></pre></div></div>

<h2 id="delivering-the-app">Delivering the app</h2>

<p>The two methods of deliver were email and Flask app.</p>

<h3 id="flask-app">Flask App</h3>

<p>A flask app was produced that would call a stripped down method of the model and return the top five results as links. This app can be viewed in its entirety in the <a href="https://github.com/LEO-E-100/custom_news">GitHub Repo</a> however it is relatively simple and gathers the RSS sources from an IFTTT system which delivers news articles to a Google Sheet which can then be loaded into Python using <code class="language-plaintext highlighter-rouge">gspread</code> the google library for Python. The data is then dynamically loaded into the HTML using the simple Flask method.</p>

<h3 id="email-app">Email App</h3>

<p>A script was written which would gather results in the same was as the Flask app but would send them via IFTTT to a specified email address. This script was then run from an Amazon Web Services server through a cron job which would run once a day. Thus delivering new recommonded stories each day to the users inbox.</p>

<h2 id="code-repo"><a href="https://github.com/LEO-E-100/custom_news">Code Repo</a></h2>

<p><em>N.B. Code samples in this post have not been run as they are not complete and would fail. Please see the repo for complete code</em></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

  </div><a class="u-url" href="/2018/01/24/custom.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Promethean Blog</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Leo Edwards</li><li><a class="u-email" href="mailto:leojpedwards@gmail.com">leojpedwards@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/leo-e-100"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">leo-e-100</span></a></li><li><a href="https://www.twitter.com/leojpedwards"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">leojpedwards</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>A place to keep my thoughts and projects</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
